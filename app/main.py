import os
import uvicorn
from typing import List, Optional, Dict, Any
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# ┘Е┘Г╪к╪и╪з╪к ╪з┘Д╪░┘Г╪з╪б ╪з┘Д╪з╪╡╪╖┘Ж╪з╪╣┘К
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

# ╪к╪н┘Е┘К┘Д ┘Е╪к╪║┘К╪▒╪з╪к ╪з┘Д╪и┘К╪ж╪й
load_dotenv()

# --- ╪е╪╣╪п╪з╪п╪з╪к ╪з┘Д╪к╪╖╪и┘К┘В ---
app = FastAPI(
    title="Nabd AI Platform",
    description="┘Е┘Ж╪╡╪й ┘Ж╪и╪╢ ┘Д┘Д╪░┘Г╪з╪б ╪з┘Д╪з╪╡╪╖┘Ж╪з╪╣┘К ╪з┘Д┘Е╪│╪к┘В┘Д",
    version="2.0.0"
)

def _parse_origins(raw: str) -> List[str]:
    return [origin.strip() for origin in raw.split(",") if origin.strip()]


def get_allowed_origins() -> List[str]:
    raw = os.getenv("CORS_ALLOW_ORIGINS")
    if raw:
        return _parse_origins(raw)

    origins: List[str] = []
    wasp_web_url = os.getenv("WASP_WEB_CLIENT_URL")
    if wasp_web_url:
        origins.append(wasp_web_url.strip())

    env = (os.getenv("ENV") or "development").lower()
    if env != "production":
        origins.extend(_parse_origins(os.getenv("CORS_DEV_ORIGINS", "http://localhost:3000")))

    # Remove duplicates while preserving order
    seen = set()
    deduped: List[str] = []
    for origin in origins:
        if origin not in seen:
            seen.add(origin)
            deduped.append(origin)
    return deduped


# ╪к┘Б╪╣┘К┘Д CORS ┘Д┘Д╪│┘Е╪з╪н ┘Д┘Д┘И╪з╪м┘З╪й ╪з┘Д╪г┘Е╪з┘Е┘К╪й ╪и╪з┘Д╪з╪к╪╡╪з┘Д
allowed_origins = get_allowed_origins()
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ┘Ж┘Е╪з╪░╪м ╪з┘Д╪и┘К╪з┘Ж╪з╪к (Pydantic Models) ---
class ChatRequest(BaseModel):
    message: str
    mode: str = "general"  # general, coder, writer, researcher
    history: List[Dict[str, str]] = []  # ╪│╪м┘Д ╪з┘Д┘Е╪н╪з╪п╪л╪й ╪з┘Д╪│╪з╪и┘В

class ChatResponse(BaseModel):
    response: str
    tool_usage: Optional[List[str]] = None

# --- ╪е╪╣╪п╪з╪п ┘Ж┘Е┘И╪░╪м ╪з┘Д┘Д╪║╪й (Groq) ---
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    raise ValueError("тЪая╕П GROQ_API_KEY is missing in .env file!")

# ┘Ж╪│╪к╪о╪п┘Е Llama 3 ┘Д┘Д╪│╪▒╪╣╪й ┘И╪з┘Д┘Г┘Б╪з╪б╪й
llm = ChatGroq(
    temperature=0.5,
    model_name="llama3-70b-8192", 
    api_key=GROQ_API_KEY
)

# --- ╪к╪╣╪▒┘К┘Б ╪з┘Д╪и╪▒┘И┘Е╪и╪к╪з╪к (System Prompts) ---
SYSTEM_PROMPTS = {
    "general": """╪г┘Ж╪к (┘Ж╪и╪╢)╪М ┘Е╪│╪з╪╣╪п ╪░┘Г┘К ┘Е╪к╪╖┘И╪▒ ┘Д┘Д┘Е╪│╪к╪о╪п┘Е┘К┘Ж ╪з┘Д╪╣╪▒╪и. 
    ┘Е┘З┘Е╪к┘Г: ╪з┘Д╪е╪м╪з╪и╪й ╪и┘И╪╢┘И╪н╪М ╪п┘В╪й╪М ┘И┘И╪п┘К╪й. ╪з╪│╪к╪о╪п┘Е ╪з┘Д┘Д╪║╪й ╪з┘Д╪╣╪▒╪и┘К╪й ╪п╪з╪ж┘Е┘Л╪з.""",
    
    "coder": """╪г┘Ж╪к ┘Е╪и╪▒┘Е╪м ╪о╪и┘К╪▒ ┘Б┘К ┘Е┘Ж╪╡╪й ┘Ж╪и╪╢.
    ┘Е┘З┘Е╪к┘Г: ┘Г╪к╪з╪и╪й ╪г┘Г┘И╪з╪п ┘Ж╪╕┘К┘Б╪й (Clean Code) ┘И╪з╪н╪к╪▒╪з┘Б┘К╪й.
    ╪з┘Д┘В┘И╪з╪╣╪п:
    1. ╪з┘Д┘Г┘И╪п ┘К╪м╪и ╪г┘Ж ┘К┘Г┘И┘Ж ┘В╪з╪и┘Д╪з┘Л ┘Д┘Д╪к┘Ж┘Б┘К╪░.
    2. ╪з╪┤╪▒╪н ╪з┘Д┘Е┘Ж╪╖┘В ╪и╪з╪о╪к╪╡╪з╪▒ ╪и╪з┘Д╪╣╪▒╪и┘К╪й╪М ┘И╪з┘Г╪к╪и ╪з┘Д┘Г┘И╪п ╪и╪з┘Д╪е┘Ж╪м┘Д┘К╪▓┘К╪й.
    3. ╪з╪к╪и╪╣ ┘Е╪╣╪з┘К┘К╪▒ PEP8 ┘Б┘К ╪и╪з┘К╪л┘И┘Ж.""",
    
    "writer": """╪г┘Ж╪к ┘Г╪з╪к╪и ┘Е╪и╪п╪╣ ┘И┘Е╪н╪к╪▒┘Б.
    ┘Е┘З┘Е╪к┘Г: ╪╡┘К╪з╪║╪й ┘Е╪н╪к┘И┘Й ╪м╪░╪з╪и╪М ╪о╪з┘Д┘К ┘Е┘Ж ╪з┘Д╪г╪о╪╖╪з╪б╪М ┘И┘Е┘Ж╪│┘В ╪и╪╣┘Ж╪з┘К╪й.
    ╪з╪│╪к╪о╪п┘Е ╪к┘Ж╪│┘К┘В Markdown ┘Д┘Д╪╣┘Ж╪з┘И┘К┘Ж ┘И╪з┘Д┘В┘И╪з╪ж┘Е.""",
    
    "researcher": """╪г┘Ж╪к ╪и╪з╪н╪л ╪г┘Г╪з╪п┘К┘Е┘К ╪п┘В┘К┘В.
    ┘Е┘З┘Е╪к┘Г: ╪к┘В╪п┘К┘Е ┘Е╪╣┘Д┘И┘Е╪з╪к ┘Е┘И╪л┘В╪й╪М ╪к╪н┘Д┘К┘Д ╪╣┘Е┘К┘В╪М ┘И╪░┘Г╪▒ ╪з┘Д┘Е╪╡╪з╪п╪▒ ╪е┘Ж ╪г┘Е┘Г┘Ж.
    ╪к╪м┘Ж╪и ╪з┘Д╪е╪м╪з╪и╪з╪к ╪з┘Д╪│╪╖╪н┘К╪й."""
}

ARABIC_ENFORCEMENT = "╪к┘Ж╪и┘К┘З ╪╡╪з╪▒┘Е: ┘К╪м╪и ╪г┘Ж ┘К┘Г┘И┘Ж ╪▒╪п┘Г ╪и╪з┘Д┘Д╪║╪й ╪з┘Д╪╣╪▒╪и┘К╪й ╪з┘Д┘Б╪╡╪н┘Й (╪г┘И ╪з┘Д┘Д┘З╪м╪й ╪з┘Д╪╣╪▒╪з┘В┘К╪й ╪е╪░╪з ╪╖┘Д╪и ╪з┘Д┘Е╪│╪к╪о╪п┘Е)╪М ┘И╪н╪з┘Б╪╕ ╪╣┘Д┘Й ╪к┘Ж╪│┘К┘В RTL."

from app.agent import agent_app

async def process_chat(request: ChatRequest) -> str:
    # 1. ╪е╪╣╪п╪з╪п ╪з┘Д╪и╪▒┘И┘Е╪и╪к ┘И╪з┘Д┘Ж╪╕╪з┘Е (┘Г┘Е╪з ┘Г╪з┘Ж ╪│╪з╪и┘В╪з┘Л)
    selected_system_prompt = SYSTEM_PROMPTS.get(request.mode, SYSTEM_PROMPTS["general"])
    full_system_message = f"{selected_system_prompt}\n\n{ARABIC_ENFORCEMENT}"

    # 2. ╪к╪м┘З┘К╪▓ ┘В╪з╪ж┘Е╪й ╪з┘Д╪▒╪│╪з╪ж┘Д
    messages = [SystemMessage(content=full_system_message)]
    
    # ╪е╪╢╪з┘Б╪й ╪з┘Д╪к╪з╪▒┘К╪о ╪з┘Д╪│╪з╪и┘В
    for msg in request.history:
        if msg["role"] == "user":
            messages.append(HumanMessage(content=msg["content"]))
        else:
            messages.append(AIMessage(content=msg["content"]))
            
    # ╪е╪╢╪з┘Б╪й ╪з┘Д╪▒╪│╪з┘Д╪й ╪з┘Д╪м╪п┘К╪п╪й
    messages.append(HumanMessage(content=request.message))

    # 3. ╪к╪┤╪║┘К┘Д ╪з┘Д┘И┘Г┘К┘Д ╪з┘Д╪░┘Г┘К (LangGraph) ЁЯЪА
    # ┘З╪░╪з ╪з┘Д╪│╪╖╪▒ ┘З┘И ╪м┘И┘З╪▒ ╪з┘Д┘Ж╪╕╪з┘Е: ╪н┘К╪л ┘К╪и╪п╪г ╪з┘Д┘И┘Г┘К┘Д ┘Б┘К ╪з┘Д╪к┘Б┘Г┘К╪▒ ┘И╪з╪│╪к╪о╪п╪з┘Е ╪з┘Д╪г╪п┘И╪з╪к
    try:
        # ┘Ж╪│╪к╪о╪п┘Е ainvoke ┘Д╪г┘Ж┘З ┘К╪п╪╣┘Е ╪з┘Д╪к╪┤╪║┘К┘Д ╪║┘К╪▒ ╪з┘Д┘Е╪к╪▓╪з┘Е┘Ж (Async)
        result = await agent_app.ainvoke({"messages": messages})
        
        # ┘Ж╪│╪к╪о╪▒╪м ╪в╪о╪▒ ╪▒╪│╪з┘Д╪й ┘Е┘Ж ╪з┘Д┘И┘Г┘К┘Д (┘И┘З┘К ╪з┘Д╪▒╪п ╪з┘Д┘Ж┘З╪з╪ж┘К ┘Д┘Д┘Е╪│╪к╪о╪п┘Е)
        last_message = result["messages"][-1]
        return last_message.content
        
    except Exception as e:
        print(f"Error: {str(e)}") # ┘Д┘Д╪к╪┤╪о┘К╪╡ ┘Б┘К ╪з┘Д╪к┘К╪▒┘Е┘К┘Ж╪з┘Д
        return "╪╣╪░╪▒╪з┘Л╪М ┘И╪з╪м┘З╪к ┘Е╪┤┘Г┘Д╪й ╪к┘В┘Ж┘К╪й ╪г╪л┘Ж╪з╪б ┘Е╪╣╪з┘Д╪м╪й ╪╖┘Д╪и┘Г. ┘К╪▒╪м┘Й ╪з┘Д┘Е╪н╪з┘И┘Д╪й ┘Е╪▒╪й ╪г╪о╪▒┘Й."

# --- ┘Ж┘В╪з╪╖ ╪з┘Д┘Ж┘З╪з┘К╪й (Endpoints) ---

@app.get("/")
async def root():
    return {"status": "online", "message": "┘Е╪▒╪н╪и╪з┘Л ╪и┘Г ┘Б┘К ┘Е┘Ж╪╡╪й ┘Ж╪и╪╢ 2.0 ЁЯЪА"}

@app.get("/api/health")
async def health_check():
    return {"status": "healthy", "model": "llama3-70b-8192"}

@app.post("/run", response_model=ChatResponse)
async def run_agent(request: ChatRequest):
    """
    ┘Ж┘В╪╖╪й ╪з┘Д┘Ж┘З╪з┘К╪й ╪з┘Д╪▒╪ж┘К╪│┘К╪й ┘Д┘Д┘Е╪н╪з╪п╪л╪й.
    ╪к╪│╪к┘В╪и┘Д ╪з┘Д╪▒╪│╪з┘Д╪й ┘И╪з┘Д┘И╪╢╪╣ (Mode) ┘И╪к╪╣┘К╪п ╪з┘Д╪▒╪п ╪з┘Д╪░┘Г┘К.
    """
    ai_reply = await process_chat(request)
    return ChatResponse(response=ai_reply)

# --- ╪к╪┤╪║┘К┘Д ╪з┘Д╪о╪з╪п┘Е (┘Д╪г╪║╪▒╪з╪╢ ╪з┘Д╪к╪╡╪н┘К╪н ╪з┘Д┘Е╪и╪з╪┤╪▒) ---
if __name__ == "__main__":
    uvicorn.run("app.main:app", host="0.0.0.0", port=5000, reload=True)
